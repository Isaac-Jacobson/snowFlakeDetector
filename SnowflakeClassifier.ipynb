{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "SnowflakeClassifier",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Snowflake Detector"
      ],
      "metadata": {
        "id": "R13NHesM1bRi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Bonus cell just for executing linux commands\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "WiJKNB-Y1Yrn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Setup"
      ],
      "metadata": {
        "id": "TbZSNoQ31n84"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qhl8lqVamEty",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d134371-d421-4160-d8d6-ece9bd2f0fc2"
      },
      "source": [
        "#Install dependecies\n",
        "!pip install -q tflite-model-maker\n",
        "!pip install -q tflite-support"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 616 kB 15.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 20.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 596 kB 51.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 49.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 234 kB 60.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 6.4 MB 28.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.4 MB 54.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 14.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 840 kB 51.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 77 kB 2.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 87 kB 7.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 120 kB 67.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 25.3 MB 1.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 99 kB 10.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 352 kB 70.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 47.7 MB 73 kB/s \n",
            "\u001b[K     |████████████████████████████████| 462 kB 72.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 211 kB 71.1 MB/s \n",
            "\u001b[?25h  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Needed imports although matplotlib, numpy,and pandas aren't currently used but will probably be needed\n",
        "import tensorflow as tf\n",
        "\n",
        "from tflite_model_maker.config import ExportFormat\n",
        "from tflite_model_maker import model_spec\n",
        "from tflite_model_maker import object_detector\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib as plt\n",
        "\n",
        "import os"
      ],
      "metadata": {
        "id": "899Xah1s-PVZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Get the data and base model"
      ],
      "metadata": {
        "id": "l9SrNd3b2Suu"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CtdZ-JDwMimd"
      },
      "source": [
        "#Picking what base model to use, efficientdet is just a starting place\n",
        "#spec = model_spec.get('efficientdet_lite0')\n",
        "#spec = model_spec.get('efficientdet_lite2')\n",
        "spec = model_spec.get('efficientdet_lite4')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Get dat data\n",
        "!curl -L \"https://app.roboflow.com/ds/fosD79eC34?key=xH3OhXG8fK\" > data.zip\n",
        "!unzip data.zip; rm data.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UrHyUD4voZq0",
        "outputId": "57839169-826d-47fb-def5-c03c950d8650"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   893  100   893    0     0   1908      0 --:--:-- --:--:-- --:--:--  1908\n",
            "100 51030  100 51030    0     0  81387      0 --:--:-- --:--:-- --:--:-- 81387\n",
            "Archive:  data.zip\n",
            "replace README.dataset.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n",
            " extracting: README.dataset.txt      \n",
            " extracting: README.roboflow.txt     \n",
            " extracting: test/Flake000011_Cam0_1_2022-1-20-20-34-21-684_bmp.rf.58d00fb155c5a3f0b2883c7382c587c9.jpg  \n",
            " extracting: test/_annotations.csv   \n",
            " extracting: train/Flake000011_Cam2_1_2022-1-20-20-34-21-679_bmp.rf.4e482ea9ea773e0ef44cce224109c207.jpg  \n",
            " extracting: train/Flake000011_Cam2_1_2022-1-20-20-34-21-679_bmp.rf.93b4abf9dbe0252d35153c2db52c0ab5.jpg  \n",
            " extracting: train/Flake000011_Cam2_1_2022-1-20-20-34-21-679_bmp.rf.cad0f5c2ef762aaa71802003a5d99f8d.jpg  \n",
            " extracting: train/Flake000011_Cam3_1_2022-1-20-20-34-21-673_bmp.rf.62351b990d1435866f818506dcffc133.jpg  \n",
            " extracting: train/Flake000011_Cam3_1_2022-1-20-20-34-21-673_bmp.rf.e2e24f594fbbab42d3404643c32a9902.jpg  \n",
            " extracting: train/Flake000011_Cam3_1_2022-1-20-20-34-21-673_bmp.rf.eee1cee5cb4f0b750a67048ca9accb45.jpg  \n",
            " extracting: train/Flake000011_Cam5_1_2022-1-20-20-34-21-669_bmp.rf.83024fac7fa69d18065bc47ed7b51079.jpg  \n",
            " extracting: train/Flake000011_Cam5_1_2022-1-20-20-34-21-669_bmp.rf.adf1c0f18d573b46eeed5e0deb584f59.jpg  \n",
            " extracting: train/Flake000011_Cam5_1_2022-1-20-20-34-21-669_bmp.rf.f5236d2d6685c63a73cac676261a87e8.jpg  \n",
            " extracting: train/_annotations.csv  \n",
            " extracting: valid/Flake000011_Cam4_1_2022-1-20-20-34-21-670_bmp.rf.b248563a2d7aa8fbd68fcf8b0a2de0cf.jpg  \n",
            " extracting: valid/_annotations.csv  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#I'm working on automating the jpeg and csv manipulation but right now I still hand format the csv\n",
        "\n",
        "#!mkdir data\n",
        "!mv ./test/*.jpg .\n",
        "!mv ./train/*.jpg .\n",
        "!mv ./valid/*.jpg .\n",
        "#!mkdir annotations\n",
        "#!mv ./test/*.csv ./annotations/test.csv\n",
        "#!mv ./train/*.csv ./annotations/train.csv\n",
        "#!mv ./valid/*.csv ./annotations/valid.csv\n",
        "#!rm ./merged.csv\n",
        "#!head -n 1 ./annotation/train.csv > merged.csv && tail -n+2 -q ./annotation/*.csv >> merged.csv"
      ],
      "metadata": {
        "id": "U1VSEsVvqwJt"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Train and test"
      ],
      "metadata": {
        "id": "st34ytea2X8R"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HD5BvzWe6YKa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18231c32-54ef-431e-8090-03fdde6ee4c9"
      },
      "source": [
        "train_data, validation_data, test_data = object_detector.DataLoader.from_csv('./data/annotations.csv')"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Cache will be stored in /tmp/tmpspnpr0sb with prefix filename train_d155c6d48da36cf8f5f39f5ad77b0b9d. Cache_prefix is /tmp/tmpspnpr0sb/train_d155c6d48da36cf8f5f39f5ad77b0b9d\n",
            "INFO:tensorflow:Cache will be stored in /tmp/tmpm3niocu1 with prefix filename val_d155c6d48da36cf8f5f39f5ad77b0b9d. Cache_prefix is /tmp/tmpm3niocu1/val_d155c6d48da36cf8f5f39f5ad77b0b9d\n",
            "INFO:tensorflow:Cache will be stored in /tmp/tmpw54uo7b8 with prefix filename test_d155c6d48da36cf8f5f39f5ad77b0b9d. Cache_prefix is /tmp/tmpw54uo7b8/test_d155c6d48da36cf8f5f39f5ad77b0b9d\n",
            "INFO:tensorflow:On image 0\n",
            "INFO:tensorflow:On image 0\n",
            "INFO:tensorflow:On image 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_data.label_map)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7q0505gI39x_",
        "outputId": "a6e84bc7-1cdf-4836-82f8-d5b9035571e6"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{1: 'class', 2: 'Snowflake'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kwlYdTcg63xy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59ad3ae7-3d0d-4a66-d43d-f72702c01ede"
      },
      "source": [
        "# train_whole_model, controls layers being trained, setting to false uses transfer learning to train and\n",
        "# only trains layers that don't match model_spec.config.var_freeze_expr.\n",
        "model = object_detector.create(train_data, model_spec=spec, epochs = 5, batch_size=1, train_whole_model=True, validation_data=validation_data)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Label map is not the same as the previous label_map in model_spec.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Label map is not the same as the previous label_map in model_spec.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Retraining the models...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Retraining the models...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "6/9 [===================>..........] - ETA: 0s - det_loss: 1.7206 - cls_loss: 1.1430 - box_loss: 0.0116 - reg_l2_loss: 0.1077 - loss: 1.8283 - learning_rate: 0.0061 - gradient_norm: 5.9389WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2706s vs `on_train_batch_end` time: 0.4071s). Check your callbacks.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2706s vs `on_train_batch_end` time: 0.4071s). Check your callbacks.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9/9 [==============================] - 69s 1s/step - det_loss: 2.0075 - cls_loss: 1.1285 - box_loss: 0.0176 - reg_l2_loss: 0.1078 - loss: 2.1153 - learning_rate: 0.0047 - gradient_norm: 7.0404 - val_det_loss: 1.5222 - val_cls_loss: 1.0992 - val_box_loss: 0.0085 - val_reg_l2_loss: 0.1078 - val_loss: 1.6300\n",
            "Epoch 2/5\n",
            "9/9 [==============================] - 7s 811ms/step - det_loss: 1.6059 - cls_loss: 1.0656 - box_loss: 0.0108 - reg_l2_loss: 0.1078 - loss: 1.7136 - learning_rate: 8.6218e-04 - gradient_norm: 6.2724 - val_det_loss: 1.4484 - val_cls_loss: 1.0642 - val_box_loss: 0.0077 - val_reg_l2_loss: 0.1078 - val_loss: 1.5562\n",
            "Epoch 3/5\n",
            "9/9 [==============================] - 5s 626ms/step - det_loss: 1.6203 - cls_loss: 1.0610 - box_loss: 0.0112 - reg_l2_loss: 0.1078 - loss: 1.7281 - learning_rate: 3.9729e-04 - gradient_norm: 4.7010 - val_det_loss: 1.4017 - val_cls_loss: 1.0397 - val_box_loss: 0.0072 - val_reg_l2_loss: 0.1078 - val_loss: 1.5095\n",
            "Epoch 4/5\n",
            "9/9 [==============================] - 6s 656ms/step - det_loss: 1.4136 - cls_loss: 0.9413 - box_loss: 0.0094 - reg_l2_loss: 0.1078 - loss: 1.5214 - learning_rate: 6.5784e-05 - gradient_norm: 4.7099 - val_det_loss: 1.3850 - val_cls_loss: 1.0298 - val_box_loss: 0.0071 - val_reg_l2_loss: 0.1078 - val_loss: 1.4928\n",
            "Epoch 5/5\n",
            "9/9 [==============================] - ETA: 0s - det_loss: 1.8300 - cls_loss: 0.9753 - box_loss: 0.0171 - reg_l2_loss: 0.1078 - loss: 1.9378 - learning_rate: 5.2490e-05 - gradient_norm: 6.7495loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "Converting ndarray to lists...\n",
            "(100, 7)\n",
            "0/100\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.01s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.00s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.200\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 1.000\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.200\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.200\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.200\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.200\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.200\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            "9/9 [==============================] - 11s 1s/step - det_loss: 1.7271 - cls_loss: 0.9579 - box_loss: 0.0154 - reg_l2_loss: 0.1078 - loss: 1.8349 - learning_rate: 6.1863e-05 - gradient_norm: 6.2356 - val_det_loss: 1.3747 - val_cls_loss: 1.0216 - val_box_loss: 0.0071 - val_reg_l2_loss: 0.1078 - val_loss: 1.4825\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "jNayYrKp3Suj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "779a7a93-e190-414c-d0df-a66e118d211c"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " keras_layer_1 (KerasLayer)  multiple                  15092016  \n",
            "                                                                 \n",
            " class_net/class-predict (Se  multiple                 6066      \n",
            " parableConv2D)                                                  \n",
            "                                                                 \n",
            " box_net/box-predict (Separa  multiple                 10116     \n",
            " bleConv2D)                                                      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 15,108,198\n",
            "Trainable params: 14,952,694\n",
            "Non-trainable params: 155,504\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Test"
      ],
      "metadata": {
        "id": "vDIhcO_w2gQR"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8xmnl6Yy7ARn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56e00cad-54ef-4796-cee2-97f47643f741"
      },
      "source": [
        "#Needs a bigger test set\n",
        "\n",
        "#Prints mAP for whole model and specifically for each piece (class)\n",
        "model.evaluate(test_data, batch_size=1)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r1/1 [==============================] - 4s 4s/step\n",
            "\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "Converting ndarray to lists...\n",
            "(100, 7)\n",
            "0/100\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.01s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.00s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.200\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 1.000\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.200\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.200\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.200\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.200\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.200\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'AP': 0.2,\n",
              " 'AP50': 1.0,\n",
              " 'AP75': 0.0,\n",
              " 'AP_/Snowflake': 0.2,\n",
              " 'AP_/class': -1.0,\n",
              " 'APl': -1.0,\n",
              " 'APm': -1.0,\n",
              " 'APs': 0.2,\n",
              " 'ARl': -1.0,\n",
              " 'ARm': -1.0,\n",
              " 'ARmax1': 0.2,\n",
              " 'ARmax10': 0.2,\n",
              " 'ARmax100': 0.2,\n",
              " 'ARs': 0.2}"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Making and Testing the tflite version"
      ],
      "metadata": {
        "id": "_SwUpxN02lZZ"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hm_UULdW7A9T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49b686f6-4b9b-4c91-bca9-245c3836f822"
      },
      "source": [
        "# Defaults to post training full integer quantization when exported to tflite file\n",
        "model.export(export_dir='.')"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow_examples.lite.model_maker.core.task.model_spec.object_detector_spec.ExportModel object at 0x7fa5a134de90>, because it is not built.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow_examples.lite.model_maker.core.task.model_spec.object_detector_spec.ExportModel object at 0x7fa5a134de90>, because it is not built.\n",
            "WARNING:absl:Found untraced functions such as restored_function_body, restored_function_body, restored_function_body, restored_function_body, restored_function_body while saving (showing 5 of 1028). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpwqfn1c63/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpwqfn1c63/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Label file is inside the TFLite model with metadata.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Label file is inside the TFLite model with metadata.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Saving labels in /tmp/tmpy84yz4jq/labelmap.txt.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Saving labels in /tmp/tmpy84yz4jq/labelmap.txt.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:TensorFlow Lite model exported successfully: ./model.tflite\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:TensorFlow Lite model exported successfully: ./model.tflite\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHYDWcljr6jq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c5fe704-9524-425f-deb0-5795c094327c"
      },
      "source": [
        "#Prints mAP for whole model and specifically for each piece (class)\n",
        "model.evaluate_tflite('model.tflite', test_data)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r1/1 [==============================] - 48s 48s/step\n",
            "\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "Converting ndarray to lists...\n",
            "(25, 7)\n",
            "0/25\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.01s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.00s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.200\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 1.000\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.200\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.200\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.200\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.200\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.200\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'AP': 0.2,\n",
              " 'AP50': 1.0,\n",
              " 'AP75': 0.0,\n",
              " 'AP_/Snowflake': 0.2,\n",
              " 'AP_/class': -1.0,\n",
              " 'APl': -1.0,\n",
              " 'APm': -1.0,\n",
              " 'APs': 0.2,\n",
              " 'ARl': -1.0,\n",
              " 'ARm': -1.0,\n",
              " 'ARmax1': 0.2,\n",
              " 'ARmax10': 0.2,\n",
              " 'ARmax100': 0.2,\n",
              " 'ARs': 0.2}"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Mount google drive for exports"
      ],
      "metadata": {
        "id": "YBhWyEhr2q0x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#link drive for easy saving, although just downloading the model is easier\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "5weWv68yCFv-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}